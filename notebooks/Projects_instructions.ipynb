{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Projects \n",
    "\n",
    "This document is there to help you sturcture your data science project. The flow of this guide will help you craft a data science project quickly and pay attention to some of the key elements of problem solving.\n",
    "\n",
    "When you are working on a data science project, these are some of the key parts that you need to work on: \n",
    "\n",
    "- Problem Statement\n",
    "- Data Acquisition\n",
    "- Data Dictionary\n",
    "- Feature extraction\n",
    "- Data Cleaning  \n",
    "- EDA and Data Visualization\n",
    "- Deriving Key insights from EDA\n",
    "- Model building\n",
    "- Evaluation \n",
    "- Deriving Key Insights from model\n",
    "- Exporting the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Problem statement\n",
    "\n",
    "You need clearly define the problem that you are solving. Typically when you are working with simple datasets like the UCI machine learning repository dataset then your problem statement is decided by your dataset. However the entire process of problem defintion involves translating business goals to analysis goals. \n",
    "\n",
    "Ideally you should choose a specific domain, choose a problem to solve then find data to solve the problem. In most cases exact data may not be available, then you can look at various data sources and combine data to get the required dataset. In practice however, you may have decided on what problem to solve on the basis of the what data is available and accessible to you. So you may have to go in the opposite direction where you need to decide on a dataset and then decide what questions I can ask of it and then attack the problem. \n",
    "\n",
    "Either way keep in mind, that in the process you need to learn about different domains.\n",
    "\n",
    "**--provide examples here--**\n",
    "\n",
    "- [ ] Clearly state your data source.\n",
    "- [ ] What type of data do you have? \n",
    "    - Structured/Unstructured.\n",
    "- [ ] What are you predicting?\n",
    "- [ ] What are your features? \n",
    "- [ ] What is your target? \n",
    "- [ ] What type of problem is it? \n",
    "    - [ ] Supervised/Unsupervised? \n",
    "    - [ ] Classification/Regression? \n",
    "- [ ] If you have to combine features to define the target, discuss that here.\n",
    "- [ ] Do you need to combine multiple data sources? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Acqusition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 3: Data Dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Feature Extraction\n",
    "\n",
    "- If you have unstructured data then in this step you need to extract features from the data to generate a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Data cleaning\n",
    "\n",
    "Some points to keep in mind: \n",
    "\n",
    "- [ ] Find missing values. \n",
    "- [ ] Find NaN and 0 values. \n",
    "- [ ] Do all columns have the same dtypes?\n",
    "- [ ] Convert dates to datetime types.\n",
    "    - [ ] You can use the python package arrow or datetime.\n",
    "- [ ] Convert categorical variables to type 'category' if working with pandas. \n",
    "- [ ] Convert strings to ints or floats if they represent numbers.\n",
    "- [ ] Standardize strings\n",
    "    - [ ] Convert them to lower case if possible.\n",
    "    - [ ] Replace spaces with underscores or dashes.\n",
    "    - [ ] Remove white spaces around the string **this is very critical**.\n",
    "    - [ ] Check of inconsistent spellings *typically done manually*.\n",
    "- [ ] Look for duplicate rows or columns.\n",
    "- [ ] Look for preprocessed columns; example: A categorical column that has been duplicated \n",
    "    with categorical labels.\n",
    "    \n",
    "A list of data cleaning libraries: https://mode.com/blog/python-data-cleaning-libraries/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 6:  Data preperation\n",
    "\n",
    "- [ ] Convert categorical features to dummy indices if you are doing regression or assign numerical labels if you are doing classification\n",
    "- [ ] Do test train split to generate a test set. Further do a train validation split, you will need to run the test train split function from sklearn twice for this purpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Exploratory Data Analysis and Data Visualization\n",
    "\n",
    "There are multiple steps that you need to take here: \n",
    "\n",
    "- [ ] Identify outliers in the datsets. Keep track of them, we want to run to train the model with the outliers and without them to see their effect.\n",
    "- [ ] Check for imbalance in the target variable. Quantify the imbalance. \n",
    "- [ ] Pairplot if possible to check the relationship between all the features and the target.\n",
    "- [ ] Look at the histogram for each variable, try to identify if you have a symmetric or normal distribution.\n",
    "- [ ] If possible plot a QQ plot to check the normality of the data. If you want more information, refer to [this](https://refactored.ai/learn/normality-tests/24c311b1936a4037b29ef78d629f1320/).\n",
    "- [ ] If its a classification problem, run a chi-square test between each categorical feature and the target to check for correlation and run ANOVE between the continuous/discrete features and the target to check for correlations.\n",
    "- [ ] If its a regression problem get pearson correlations between the continuous features and target and run ANOVA between each categorical variable and target.\n",
    "- Check for correlations between individual features; use similar approaches as you did with the target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Key Insights from EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Model evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Key Insights from Predictive analsis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Exporting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
